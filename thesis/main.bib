@inproceedings{diffpriv_original,
  author    = {Dwork, Cynthia
    and McSherry, Frank
    and Nissim, Kobbi
    and Smith, Adam},
  editor    = {Halevi, Shai
    and Rabin, Tal},
  title     = {Calibrating Noise to Sensitivity in Private Data Analysis},
  booktitle = {Theory of Cryptography},
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {265--284},
  abstract  = {We continue a line of research initiated in [10,11]on privacy-preserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function f mapping databases to reals, the so-called true answer is the result of applying f to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user.},
  isbn      = {978-3-540-32732-5}
}

@inproceedings{revealing_information,
  author    = {Dinur, Irit and Nissim, Kobbi},
  title     = {Revealing Information While Preserving Privacy},
  year      = {2003},
  isbn      = {1581136706},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/773153.773173},
  doi       = {10.1145/773153.773173},
  abstract  = {We examine the tradeoff between privacy and usability of statistical databases. We model a statistical database by an n-bit string d1,..,dn, with a query being a subset q ⊆ [n] to be answered by Σiεq di. Our main result is a polynomial reconstruction algorithm of data from noisy (perturbed) subset sums. Applying this reconstruction algorithm to statistical databases we show that in order to achieve privacy one has to add perturbation of magnitude (Ω√n). That is, smaller perturbation always results in a strong violation of privacy. We show that this result is tight by exemplifying access algorithms for statistical databases that preserve privacy while adding perturbation of magnitude \~{O}(√n).For time-T bounded adversaries we demonstrate a privacypreserving access algorithm whose perturbation magnitude is ≈ √T.},
  booktitle = {Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
  pages     = {202–210},
  numpages  = {9},
  keywords  = {subset-sums with noise, data reconstruction, integrity and security},
  location  = {San Diego, California},
  series    = {PODS '03}
}

@article{dalenius1977,
  title   = {Towards a methodology for statistical disclosure control},
  author  = {Dalenius, Tore},
  journal = {statistik Tidskrift},
  volume  = {15},
  number  = {429-444},
  pages   = {2--1},
  year    = {1977}
}

@incollection{dwork2006_diffpriv,
  doi       = {10.1007/11787006_1},
  url       = {https://doi.org/10.1007/11787006_1},
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  pages     = {1--12},
  author    = {Cynthia Dwork},
  title     = {Differential Privacy},
  booktitle = {Automata,  Languages and Programming}
}

@article{reidentification2011,
  author  = {Emam, Khaled and Jonker, Elizabeth and Arbuckle, Luk and Malin, Bradley},
  year    = {2011},
  month   = {12},
  pages   = {e28071},
  title   = {A Systematic Review of Re-Identification Attacks on Health Data},
  volume  = {6},
  journal = {PloS one},
  doi     = {10.1371/journal.pone.0028071}
}
