@inproceedings{revealing_information,
  author    = {Dinur, Irit and Nissim, Kobbi},
  title     = {Revealing Information While Preserving Privacy},
  year      = {2003},
  isbn      = {1581136706},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/773153.773173},
  doi       = {10.1145/773153.773173},
  abstract  = {We examine the tradeoff between privacy and usability of statistical databases. We model a statistical database by an n-bit string d1,..,dn, with a query being a subset q ⊆ [n] to be answered by Σiεq di. Our main result is a polynomial reconstruction algorithm of data from noisy (perturbed) subset sums. Applying this reconstruction algorithm to statistical databases we show that in order to achieve privacy one has to add perturbation of magnitude (Ω√n). That is, smaller perturbation always results in a strong violation of privacy. We show that this result is tight by exemplifying access algorithms for statistical databases that preserve privacy while adding perturbation of magnitude \~{O}(√n).For time-T bounded adversaries we demonstrate a privacypreserving access algorithm whose perturbation magnitude is ≈ √T.},
  booktitle = {Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
  pages     = {202–210},
  numpages  = {9},
  keywords  = {subset-sums with noise, data reconstruction, integrity and security},
  location  = {San Diego, California},
  series    = {PODS '03}
}

@article{dalenius1977,
  title   = {Towards a methodology for statistical disclosure control},
  author  = {Dalenius, Tore},
  journal = {statistik Tidskrift},
  volume  = {15},
  number  = {429-444},
  pages   = {2--1},
  year    = {1977}
}

@incollection{dwork2006_diffpriv,
  doi       = {10.1007/11787006_1},
  url       = {https://doi.org/10.1007/11787006_1},
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  pages     = {1--12},
  author    = {Cynthia Dwork},
  title     = {Differential Privacy},
  booktitle = {Automata,  Languages and Programming}
}

@incollection{dworketal2006,
  doi       = {10.1007/11681878_14},
  url       = {https://doi.org/10.1007/11681878_14},
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  pages     = {265--284},
  author    = {Cynthia Dwork and Frank McSherry and Kobbi Nissim and Adam Smith},
  title     = {Calibrating Noise to Sensitivity in Private Data Analysis},
  booktitle = {Theory of Cryptography}
}

@article{reidentification2011,
  author  = {Emam, Khaled and Jonker, Elizabeth and Arbuckle, Luk and Malin, Bradley},
  year    = {2011},
  month   = {12},
  pages   = {e28071},
  title   = {A Systematic Review of Re-Identification Attacks on Health Data},
  volume  = {6},
  journal = {PloS one},
  doi     = {10.1371/journal.pone.0028071}
}

@incollection{dwork2006_delta_diffpriv,
  doi       = {10.1007/11761679_29},
  url       = {https://doi.org/10.1007/11761679_29},
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  pages     = {486--503},
  author    = {Cynthia Dwork and Krishnaram Kenthapadi and Frank McSherry and Ilya Mironov and Moni Naor},
  title     = {Our Data,  Ourselves: Privacy Via Distributed Noise Generation},
  booktitle = {Advances in Cryptology - {EUROCRYPT} 2006}
}

@inproceedings{microsoft_telemetry,
  author    = {Ding, Bolin and Kulkarni, Janardhan and Yekhanin, Sergey},
  title     = {Collecting Telemetry Data Privately},
  year      = {2017},
  isbn      = {9781510860964},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {The collection and analysis of telemetry data from user's devices is routinely performed by many software companies. Telemetry collection leads to improved user experience but poses significant risks to users' privacy. Locally differentially private (LDP) algorithms have recently emerged as the main tool that allows data collectors to estimate various population statistics, while preserving privacy. The guarantees provided by such algorithms are typically very strong for a single round of telemetry collection, but degrade rapidly when telemetry is collected regularly. In particular, existing LDP algorithms are not suitable for repeated collection of counter data such as daily app usage statistics. In this paper, we develop new LDP mechanisms geared towards repeated collection of counter data, with formal privacy guarantees even after being executed for an arbitrarily long period of time. For two basic analytical tasks, mean estimation and histogram estimation, our LDP mechanisms for repeated data collection provide estimates with comparable or even the same accuracy as existing single-round LDP collection mechanisms. We conduct empirical evaluation on real-world counter datasets to verify our theoretical results. Our mechanisms have been deployed by Microsoft to collect telemetry across millions of devices.},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages     = {3574–3583},
  numpages  = {10},
  location  = {Long Beach, California, USA},
  series    = {NIPS'17}
}
